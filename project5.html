<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chicago Real Estate Web Scraping and Analysis</title>
    <style>
        ul {
            list-style-type: square; /* Change to disc, circle, square, or none */
        }
    </style>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <a href="index.html" class="return-button">
            <button>Return to Index</button>
        </a>
        <h1>Chicago Real Estate Web Scraping and Analysis</h1>
    </header>
    <section>
        <h2>Project Overview</h2>
        <p>This project involved scraping Chicago real estate listings from online sources and performing analysis. A Python script was created to handle the scraping process and compile a dataset, and Power BI desktop was used to clean the dataset, perform analysis, and provide visualizations. The goal was to identify patterns in rental prices, assess neighborhood livability, and explore factors affecting pricing across different ZIP codes in Chicago. </p>
        <p>Key libraries used:</p>
        <ul>
            <li><strong>Selenium</strong>: Python library used to navigate and extract real estate data from web pages. </li>
        </ul>
    </section>
    <section>
        <h2>Source Considerations</h2>
        <p>To begin, I inspected listings from different sources to see what kind of information was consistently provided about the rental units. I also had to ensure through the sites' robots.txt that I could use the data collected for eductational purposes. Considering what was most often provided and what might provide interesting insight into the state of Chicago's real estate situation, I selected these attributes for the dataset:</p>
        <ul>
            <li><strong>Title:</strong> The name of the building housing the unit</li>
            <li><strong>Address:</strong> The address given for the unit</li>
            <li><strong>City:</strong> City given for the unit</li>
            <li><strong>State:</strong> State given for the unit</li>
            <li><strong>Zip:</strong> ZIP code given for the unit</li>
            <li><strong>Price:</strong> Monthly rent cost of the unit in dollars</li>
            <li><strong>Beds:</strong> Number of bedrooms for the unit</li>
            <li><strong>Baths:</strong> Number of bathrooms for the unit</li>
            <li><strong>Area:</strong> Area in square feet for the unit</li>
            <li><strong>Walk_Score:</strong> Score from 1-100 describing the unit location's walkablility</li>
            <li><strong>Transit_Score:</strong> Score from 1-100 describing the ease of access to the unit location's public transport</li>
            <li><strong>Bike_Score:</strong> Score from 1-100 describing the unit location's bike friendliness</li>
        </ul>

    </section>
    <section>
        <h2>Web Scraping</h2>
        <p>Initially, I used the Python library BeautifulSoup for scraping, but most listings were loaded dynamically  and weren't found in the raw source html. Due to these restraints, I switched to the library Selenium and implemented grid-based scraping by iterating through map coordinates to fetch pertinent listing pages, then extracted the dataset features from each page. The system I used for scraping is as follows:</p>
        <ul>
            <li><strong>Collect listing urls:</strong> Each summary card returned in a search links to a more detailed listing page containing the pertinent information for the dataset. These summary cards load in up to 20 pages of 41 cards based on the positioning of an interactive map. By moving the interactive map systematically, every page url link can be extracted. To properly load and store all of these urls:
                <ol>
                    <li>Set maximum and minimum direction boundaries based on the map space of interest</li>
                    <li>Set starting north, south, east, and west boundaries; this is a "sector" of the map</li>
                    <li>Increase north and south coordinates by .0136 to move up one map sector</li>
                    <li>Iterate through every page at this sector, fetch and store all listing urls in a csv</li>
                    <li>Repeat (3-4) until the current north coordinate is greater than the direction boundary from (1)</li>
                    <li>When the north coordinate is greater, return to the original starting sector but add x * .0247 to the east and west coordinates, where x is the number of times the north boundary has been reached. This will move left one map sector. Repeat (3-4).</li>
                    <li>Stop when the current west coordinate is greater than the maximum west boundary</li>
                </ol>
            </li>
            <li><strong>Collect listing details:</strong> After all urls have been collected, iterate through each, fetch all pertinent details, and append them as a row to a csv.
            </li>
        </ul>
        <p>Below is a summary of key statistical measures for the final datasetâ€™s numerical columns, generated using the Pandas describe() function.
            <br>
            <img src="images/real_est_dataset_description.png" alt="df describe">
        </p>

    </section>
    <section>
        <h2>Data Mining & Analysis</h2>
        <p>After gathering the data, I processed and analyzed it using Power BI. Key analyses included:</p>
        <ul>
            <li><strong>Price Distribution:</strong> Created histograms and box plots to visualize rent price ranges.</li>
            <li><strong>Geospatial Analysis:</strong> Used filled maps to highlight rental price variations by ZIP code.</li>
            <li><strong>Neighborhood Livability:</strong> Assessed walkability, transit accessibility, and bike-friendliness by area.</li>
            <li><strong>Correlation Analysis:</strong> Examined relationships between rent prices and features like square footage and number of bedrooms.</li>
        </ul>
    </section>
    <section>
        <h2>Data Visualization in Power BI</h2>
        <p>The data was structured into an interactive dashboard, allowing users to filter and explore various attributes.</p>
        <ul>
            <li>Heatmap for viewing selected attribute trends by ZIP code.
            <br>
            <video width="800" controls>
                <source src="videos/real_est_var_heatmap_vid.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            </li>
            <li>Stacked column charts comparing walk, transit, and bike scores across ZIP codes.
            <br>
            <video width="800" controls>
                <source src="videos/real_est_stacked_columns.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            </li>
            <li>Scatter plots to identify pricing trends across the top and bottom 10 ZIP codes.
            <br>
            <video width="800" controls>
                <source src="videos/real_est_top10.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            </li>
            <li>Tree maps to visualize price distributions across different ranges.
            <br>
            <video width="800" controls>
                <source src="videos/real_est_treemap.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            </li>
        </ul>
    </section>
    <section>
        <h2>Key Findings</h2>
        <ul>
            <li>ZIP codes having a higher average monthly rent price tend to have higher neighborhood scores</li>
            <li>88% of listings have monthly rent costs greater than $1,500, 1% of listings have rent costs less than $1,000</li>
            <li>Area and rent price have a positive correlation: as one increases or decreases, so does the other</li>
            <li>Downtown ZIP codes win out in all average metrics except for price and area</li>
        </ul>
    </section>
    <section>
        <h2>Code and Implementation</h2>
        <p>The source code for this project is available on <a href="https://github.com/Keegodude/real-estate-scraping">GitHub</a>. The following files are included:</p>
        <ul>
            <li><strong>url_assembly.py</strong>: Script for scraping all listing urls.</li>
            <li><strong>rent_data_assembly.py</strong>: Script that collects listing details from list of urls.</li>
            <li><strong>requirements.txt</strong>: List of required Python packages.</li>
        </ul>
    </section>
    <section>
        <h2>Future Work</h2>
        <p>Next steps could include incorporating more features to the dataset such as unit type(condo, apartment, house) or popular amentities(pets allowed, gym, personal parking).
            More cities and states can easily be incorporated using the same scraping scripts.
        </p>
    </section>
    <section>
        <h2>Project Takeaways</h2>
        <p>Before this project, I had never applied web scraping other than in very simple academic work.
            Now, I know how to use libraries that allow for scraping dynamic sources rather than only the source html.
            In addition, I learned a few techniques to decrease the likelihood of anti-bot or captcha detection.
        </p>
        <p>Outside of Python, I used Power BI for the first time here. I've used Tableau before, and I felt that some knowledge of that
        carried over to Power BI. I gained some experience using DAX and Power Query to manipulate data and provide the visualizations that I wanted to.</p>
    </section>
</body>
</html>
</title>
</head>
<body>

</body>
</html>